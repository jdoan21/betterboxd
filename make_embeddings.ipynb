{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "make_embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u22W22935FZa"
      },
      "source": [
        "# Goal of this File\n",
        "Create a json file `image_embeddings.json` of the following format\n",
        "```\n",
        "{\n",
        "  'movie_id': {\n",
        "      'clip': Float[],\n",
        "      'resnet50': Float[]\n",
        "  }\n",
        "}\n",
        "```\n",
        "which contains the representations of a movie poster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IozdcgNk5a8L",
        "outputId": "f6f5541f-fecd-4a46-b545-ea4b250be7fd"
      },
      "source": [
        "# this mounts your Google Drive to the Colab VM.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "\n",
        "FOLDERNAME = 'cs229_proj/'\n",
        "\n",
        "\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "# now that we've mounted your Drive, this ensures that\n",
        "# the Python interpreter of the Colab VM can load\n",
        "# python files from within it.\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
        "\n",
        "%cd drive/My\\ Drive/$FOLDERNAME/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/.shortcut-targets-by-id/1FYI1gIgILgT31h2y_QMmBZOwkDqTPrg-/cs229_proj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "761s6ICg5mB8"
      },
      "source": [
        "!ls\n",
        "!pip install ftfy regex tqdm\n",
        "!pip install git+https://github.com/openai/CLIP.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JGhpFHk5p9a"
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from PIL import Image # for viewing images\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import time\n",
        "import copy\n",
        "from collections import defaultdict\n",
        "\n",
        "import torch\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from poster_dataset import PosterDataset\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcDEhy8j5qSv"
      },
      "source": [
        "# Uses folder and movie_id to create path where image can be found and displayed\n",
        "\n",
        "def get_poster_path(movie_id, movie_data):\n",
        "    folder_num = str(movie_data[3]) + \"/\"\n",
        "    img_name = movie_id + '.jpg'\n",
        "    return '/content/drive/My Drive/cs229_proj/letterboxd_posters/' + folder_num + img_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksIoyV8o6VYc"
      },
      "source": [
        "movies_full_path = '/content/drive/My Drive/cs229_proj/movies_full.csv'\n",
        "\n",
        "movies_full_df = pd.read_csv(movies_full_path)\n",
        "# movies_full_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufyOYtjf6WRk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HhSNkEI6iSs"
      },
      "source": [
        "# Resnet50 Embeddings\n",
        "from torchvision.models import resnet50\n",
        "resnet_model = resnet50(pretrained=True)\n",
        "for param in resnet_model.parameters():\n",
        "    param.requires_grad = False\n",
        "resnet_model.eval()\n",
        "\n",
        "resnet_transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "resnet_dataset = PosterDataset('letterboxd_posters/', movies_full_df, range(len(movies_full_df)), resnet_transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijgD8BGK7QxC"
      },
      "source": [
        "'''\n",
        "# sanity check resnet\n",
        "output = resnet_model(resnet_dataset[0][0].unsqueeze(0))\n",
        "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
        "plt.plot(probabilities.log())\n",
        "# Read the categories\n",
        "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "    categories = [s.strip() for s in f.readlines()]\n",
        "# Show top categories per image\n",
        "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
        "for i in range(top5_prob.size(0)):\n",
        "    print(categories[top5_catid[i]], top5_prob[i].item())\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlGzC_ha_NWo"
      },
      "source": [
        "# CLIP:\n",
        "import clip\n",
        "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjIVU9QvA2P1"
      },
      "source": [
        "clip_dataset = PosterDataset('letterboxd_posters/', movies_full_df, range(len(movies_full_df)), preprocess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvS4I3qv9R4H",
        "outputId": "cd8cb4cd-f712-417e-eaaf-f39d8241a56d"
      },
      "source": [
        "embeddings = defaultdict(dict)\n",
        "for i in tqdm(range(len(movies_full_df))):\n",
        "  movie_id = movies_full_df['movie_id'][i]\n",
        "  embeddings[movie_id]['resnet'] = resnet_model(resnet_dataset[i][0].unsqueeze(0))[0].tolist()\n",
        "  embeddings[movie_id]['clip'] = clip_model.encode_image(clip_dataset[i][0].unsqueeze(0)).reshape(512,).tolist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2220/2220 [23:50<00:00,  1.55it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3z0sI-19Vpi"
      },
      "source": [
        "with open('embeddings.json', 'w') as fp:\n",
        "    json.dump(embeddings, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2RUnwB3-kLn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}